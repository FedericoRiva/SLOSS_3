## Riva anf Fahrig 2022
## Generalities in SLOSS

# prepare data
library(data.table)
library(tidyr)
library(dplyr)
library(purrr)
library(rlist)
library(splitstackshape)

# diversity estimation
library(iNEXT)
library(SpadeR)
library(vegan)
library(paleotree)

# plotting
library(ggplot2)
library(ggthemes)
library(ggpubr)
library(ggeffects)

# modeling
library(glmmTMB)
library(DHARMa)

# remove scientific notation
options(scipen=999)
set.seed(654)
#memory.limit(size=30000) # increase default memory use to 32 gb = 32000 (1 gb = 1000 mb)

## open FragSAD dataset available at https://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/ecy.2861
## .csv data and metadata provided for convenience
## open FragSAD dataset
data = fread("C:\\Users\\feder\\OneDrive\\Desktop\\Riva Fahrig SLOSS #2\\data\\fragSAD_predicts_ewers.csv", header = TRUE)
metadata = fread("C:\\Users\\feder\\OneDrive\\Desktop\\Riva Fahrig SLOSS #2\\data\\new_meta_2_merge.csv", header = TRUE)
metadata_original = fread("C:\\Users\\feder\\OneDrive\\Desktop\\Riva Fahrig SLOSS #2\\data\\FragSAD_metadata_original.csv", header = TRUE)

metadata$dataset_id <- as.factor(metadata$dataset_id)
data$dataset_label <- as.factor(data$dataset_label)

papers_reassessment = fread("C:\\Users\\feder\\OneDrive\\Desktop\\Riva Fahrig SLOSS #2\\data\\papers_reassessment.csv", header = TRUE)
papers_reassessment_filter <- papers_reassessment[,c(2,3)]
#data$frag_id <- as.factor(data$frag_id)

## data cleaning 
## remove 'continuous' patches for which we don't have real size
data <- subset(data, data$frag_size_char != 'continuous') 
## remove studies that I assessed on a one-by-one basis
data <- merge(data, papers_reassessment_filter, by = 'dataset_label')
data <- subset(data, data$included == 1) 

## remove patches with patch size assigned arbitrarily or with patch size larger than 50% of the total HA; see "paper_reassessment"
## unless otherwise stated, removed only arbitrary sized large patches
## datasets where inspected by FR
data <- data[!(data$dataset_label == "Almeida-Gomes_2014" & data$frag_size_num > 7000),] 
data <- data[!(data$dataset_label == "Baz_1995" & data$frag_size_num > 1000),] # largest patch bigger than 50%
data <- data[!(data$dataset_label == "Bell_2006_a" & data$frag_size_num > 1000),] 
data <- data[!(data$dataset_label == "Bell_2006_b" & data$frag_size_num > 1000),] 
data <- data[!(data$dataset_label == "Benedick_2006" & data$frag_size_num > 5000),] # two large patches removes in addition to arbitrary control forests
data <- data[!(data$dataset_label == "Berg_1997" & data$frag_size_num > 999),] 
data <- data[!(data$dataset_label == "Bernard_2007" & data$frag_size_num > 350),] # one large patch removed in addition to arbitrary 750 ha controls
data <- data[!(data$dataset_label == "Bolger_1997" & data$frag_size_num > 999),] 
data <- data[!(data$dataset_label == "Bragagnolo_2007" & data$frag_size_num > 999),] 
data <- data[!(data$dataset_label == "Cabrera-Guzman_2012" & data$frag_size_num > 500),] 
data <- data[!(data$dataset_label == "Davies_2003" & data$frag_size_num > 100),] 
data <- data[!(data$dataset_label == "Gavish_2012_a" & data$frag_size_num > 100),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Gavish_2012_b" & data$frag_size_num > 100),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Gavish_2012_c" & data$frag_size_num > 100),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Giladi_2011_a" & data$frag_size_num > 100),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Giladi_2011_c" & data$frag_size_num > 100),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Giladi_2011_b" & data$frag_size_num > 35),] # remove three large patches that are too larger to compare HA 
data <- data[!(data$dataset_label == "Jung_2014" & data$frag_size_num > 999),] 
data <- data[!(data$dataset_label == "Lima_2015" & data$frag_size_num > 800),] # remove two large patches that are too larger to compare HA
data <- data[!(data$dataset_label == "Manu_2007" & data$frag_size_num > 500),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Montgomery_2014" & data$frag_size_num > 3000),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Nogueira_2016" & data$frag_size_num > 200),] 
data <- data[!(data$dataset_label == "Nyeko_2009" & data$frag_size_num > 200),] 
data <- data[!(data$dataset_label == "Owen_2008" & data$frag_size_num > 200),] 
data <- data[!(data$dataset_label == "Raheem_2009" & data$frag_size_num > 15000),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Silva_2009" & data$frag_size_num > 999),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Slade_2013" & data$frag_size_num > 100),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Struebig_2008" & data$frag_size_num > 15000),] 
data <- data[!(data$dataset_label == "Vulinec_2008" & data$frag_size_num > 70),] # remove two large patches that are too larger to compare HA
data <- data[!(data$dataset_label == "Vasconcelos_2006" & data$frag_size_num > 999),] 
data <- data[!(data$dataset_label == "Brosi_2008" & data$frag_size_num > 200),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Lambert_2003" & data$frag_size_num > 300),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Savilaakso_2009" & data$frag_size_num > 250),] 
data <- data[!(data$dataset_label == "Wang_2012" & data$frag_size_num > 999),] # remove large patch that is larger than 50% HA
data <- data[!(data$dataset_label == "Kapoor_2008" & data$frag_size_num > 1999),] 



## remove site filtering column
data <- data[,-c(10)]
## label as factor
data$dataset_label <- as.factor(data$dataset_label)

## create a unique ID for study name and its patches
data$study_and_patch <- as.factor(paste(data$dataset_label, data$frag_id))




## in "patches", each row represent a patch in the original data
patches <- data[, c(1,2,10,5)]
patches<- unique(patches)

## in "assemblages" and "individuals", every row represents one taxon observed in a patch
assemblages <-  data[,c(1,2,10,8,9)] 
individuals <- assemblages[,-c(4)]

# create lists where each study is one element of a list and replace studies where 
# abundance data are reported as non-integers with that value multiplied by 100
list_individuals <- list()
for (i in 1 : 75){list_individuals[[i]] <- subset(individuals,dataset_label == levels(individuals$dataset_label)[i] )}
# Kappes_2009, Lambert_2003 and Dickman_1987 are expressed as density per area or trap; multiply by 100 to obtain integer values
for (i in 1 : 75){if (min(list_individuals[[i]]$abundance) < 1) {list_individuals[[i]]$abundance <- (list_individuals[[i]]$abundance * 100)}}  
individuals <- do.call(rbind.data.frame, list_individuals)

# number of individuals sampled in each patch
study_individuals <- aggregate(abundance ~ dataset_label, data=individuals, FUN=sum)
patch_individuals <- aggregate(abundance ~ study_and_patch, data=individuals, FUN=sum)
study_total_area <- aggregate(frag_size_num ~ dataset_label, data=patches, FUN=sum)

# add information to the dataset borrowing from original data
patch_individuals$dataset_label <- individuals$dataset_label[match(patch_individuals$study_and_patch,individuals$study_and_patch)]
patch_individuals$frag_id <- individuals$frag_id[match(patch_individuals$study_and_patch,individuals$study_and_patch)]
patch_individuals$total_abundance <- study_individuals$abundance[match(patch_individuals$dataset_label,study_individuals$dataset_label)]
patch_individuals$patch_area <- patches$frag_size_num[match(patch_individuals$study_and_patch,patches$study_and_patch)]
patch_individuals$total_patch_area <- study_total_area$frag_size_num[match(patch_individuals$dataset_label,study_total_area$dataset_label)]

# # reorder dataframe columns
# patch_individuals <- patch_individuals[c(3,4,1,6,7,2,5)]

# calculate the proportion of individuals per patch
patch_individuals$abundance_per_ha <- patch_individuals$abundance / patch_individuals$patch_area
patch_individuals$relative_patch_size <- patch_individuals$patch_area / patch_individuals$total_patch_area
# calculate the minimum to define the # of individuals simulated 
min_abundance_per_ha_study <- aggregate(abundance_per_ha ~ dataset_label, data=patch_individuals, FUN=min)
colnames(min_abundance_per_ha_study)[2] <- "min_abundance_per_ha_study"

# merge with patch-level information
patch_individuals <- merge(patch_individuals, min_abundance_per_ha_study, by = 'dataset_label')
patch_individuals$simulation_constant_abundance <- patch_individuals$min_abundance_per_ha_study * patch_individuals$patch_area


# sum(patch_individuals$simulation_constant_abundance < 1)
# 162 patches out of 1186 have a number of individuals sampled < 1, 491 < 10, 964 < 100

# study_info <- merge(study_individuals, study_total_area,  by = 'dataset_label')
# study_info <- merge(study_info, min_abundance_per_ha_study,  by = 'dataset_label')



# create lists where each study is one element of a list
list_patches <- list()
for (i in 1 : 75){list_patches[[i]] <- subset(patches,dataset_label == levels(data$dataset_label)[i] )}

list_assemblages <- list()
for (i in 1 : 75){list_assemblages[[i]] <- subset(assemblages,dataset_label == levels(data$dataset_label)[i] )}

# # subset and inspect lists with values < 1
# list_assemblages_min_one <- subset(list_assemblages, min(abundance)<1)

# if the smallest value of a list is < 1, multiply all the abundances of the species recorded as relative occurrences for 100 
# so that rows can be created proportionally to their incidence
for (i in 1 : 75){if (min(list_assemblages[[i]]$abundance) < 1) {list_assemblages[[i]]$abundance <- (list_assemblages[[i]]$abundance * 100)}}  

# extend so that each row has nrow = nindividuals
for (i in 1 : 75) {list_assemblages[[i]] <- splitstackshape::expandRows(list_assemblages[[i]], "abundance") }
list_assemblages2 <- rbindlist(list_assemblages)

# pryr::object_size(list_assemblages2)
# pryr::mem_used()

list_assemblages_patches <- list()
for (i in 1 : nlevels(list_assemblages2$study_and_patch)) {list_assemblages_patches[[i]] <-  subset(list_assemblages2,study_and_patch == levels(list_assemblages2$study_and_patch)[i] )}

# create 100 number of individuals sampled per patch
list_sim_individuals <- list()
for (i in 1 : nrow(patch_individuals)){ 
  list_sim_individuals[[i]] <- replicate(100, (floor(patch_individuals$simulation_constant_abundance[[i]]) + rbinom(1, 1,(patch_individuals$simulation_constant_abundance[[i]] - floor(patch_individuals$simulation_constant_abundance[[i]])))))
}

## potentially replace with function
##
# bin_abu <- function(x) {
#   floor(x) + rbinom(1,1,x - floor(x))
# }
# replicate(100,bin_abu(patch_individuals$simulation_constant_abundance[[i]]))
##

sim_ind <- do.call(rbind.data.frame, list_sim_individuals)
min(rowSums(sim_ind)) # every patch as at least one scenario with one individual sampled
hist(log10(rowSums(sim_ind)))

## TEST IF SIMULATIONS ARE CORRECT: check if simulations are bigger than the number of individuals observed in a patch
# list_test_sim <- rep( list(list()), 1186 )
# for (i in 1:100){
#   for (k in 1: 1186){
#     list_test_sim[[k]][i] <- isTRUE(sim_ind[k,i] > patch_individuals[k, 3])
#  }
# }
# 
# test_sim <- do.call(rbind.data.frame, list_test_sim)
# any(test_sim==TRUE)
## none of the simulated # of individuals in each patch is larger than the original number of individuals observed


### SAMPLE ROWS ON A PER-PATCH BASIS TO HAVE # OF INDIVIDUALS PROPORTIONAL TO PATCH SIZE
get_rows <- function(df, rows) df[rows, , drop = FALSE]

# split_data <- split(list_assemblages2, list_assemblages2$study_and_patch)
# group_sizes <- vapply(split_data, nrow, integer(1))
# n <-sim_ind[,3]
# sampled_obs <- mapply(sample, group_sizes, n)
# sampled_data <- mapply(get_rows, split_data, sampled_obs, SIMPLIFY = FALSE)
# sampled_data2 <- do.call(rbind, sampled_data)


# followed https://jennybc.github.io/purrr-tutorial/ls12_different-sized-samples.html
list_sampled_data <- list()
split_data <- split(list_assemblages2[,1:4], list_assemblages2$study_and_patch)
group_sizes <- vapply(split_data, nrow, integer(1))

for (i in 1:100){
  n <-sim_ind[,i]
  sampled_obs <- mapply(sample, group_sizes, n)
  sampled_data <- mapply(get_rows, split_data, sampled_obs, SIMPLIFY = FALSE)
  sampled_data2 <- do.call(rbind, sampled_data) 
  
  list_sampled_data[[i]] <- sampled_data2
}


# ## if needed, break in lists
for (i in 1:100){
  list_sampled_data[[i]] <- split(list_sampled_data[[i]], list_sampled_data[[i]][,3]) #
}


# convert from a series of rows each representing a sampled individuals, into a vectors of abundances per patch
# when a patch has zero simulated individuals, this still create a column that I will remove later to avoid losing the patch from the dataset
for (i in 1:length(list_sampled_data)){
  for (j in 1:length(list_sampled_data[[i]])){
    if(nrow(list_sampled_data[[i]][j][[1]]) == 0) {
      mydf <- (data.frame(Var1 = "no_species_present", Freq = 0))
      list_sampled_data[[i]][j][[1]]<- setNames(data.frame(t(mydf[,-1])), mydf[,1])
    } else {
      list_sampled_data[[i]][j][[1]] <- setNames(data.frame(t(as.data.frame(table(list_sampled_data[[i]][j][[1]]$species))[,-1])), as.data.frame(table(list_sampled_data[[i]][j][[1]]$species))[,1])
    }
  }
}



# split the 100 lists into 75 datasets
study_index <- patches$dataset_label
for (i in 1: length(list_sampled_data)){
  list_sampled_data[[i]] <- split(list_sampled_data[[i]], study_index)
}

# function to convert list of vectors of species abundances into table
to_table <- function(list_to_table) {
  table_prova <- rbindlist(lapply(list_to_table, function(x) as.data.frame.list(x)), fill=TRUE)
  table_prova[is.na(table_prova)] <- 0
  table_prova$study_and_patch <- names(list_to_table)
  list_to_table <- table_prova
}

# make each list (100 simulations per 75 studies) into a table of species per sites
for (i in 1:length(list_sampled_data)){
  for (j in 1: length(list_sampled_data[[i]])){
    list_sampled_data[[i]][[j]] <- to_table(list_sampled_data[[i]][[j]]) #rbindlist(lapply(list_sampled_data[[i]][[j]], function(x) as.data.frame.list(x)), fill=TRUE)
  }
}

# remove empty column that was necessary to retain patches with zero simulated individuals
for (i in 1:length(list_sampled_data)){
  for (j in 1: length(list_sampled_data[[i]])){
    
    if("no_species_present" %in% colnames(list_sampled_data[[i]][j][[1]])){
      list_sampled_data[[i]][j][[1]] <- select(list_sampled_data[[i]][j][[1]], -no_species_present)
    } 
    
  }
}

# TEST: did we remove the "no_species_present" column added to retain empty patches? Note that empty patches must be retained for the simulations 
# list_sampled_data[[1]][74][[1]] # does not have the "no_species_present" column anymore

# add patch size to each list
list_patches_unlisted <- do.call(rbind.data.frame, list_patches)
list_patches_unlisted <- list_patches_unlisted[,3:4]

for (i in 1:length(list_sampled_data)){
  for (j in 1: length(list_sampled_data[[i]])){
    
    list_sampled_data[[i]][j][[1]] <- merge(list_sampled_data[[i]][j][[1]], list_patches_unlisted, by = "study_and_patch")
    
  }
}




## ELE analysis
#### sloss function from Lexiguel
sloss <- function(table, env=data.frame(), area) {
  if(!is.matrix(table)) table <- as.matrix(table)
  area <- substitute(area)
  area <- eval(area, env, parent.frame())
  SLOSS <- list(SL=list(), LS=list())
  # First the calculation from small to large
  SLOSS$SL$area <- c(0, cumsum(area[order(area)]))
  Flor <- apply(table[order(area),], 2, cumsum)
  Flor[Flor > 0] <- 1
  SLOSS$SL$species <- c(0, apply(Flor, 1, sum))
  # Now the calculation from large to small
  SLOSS$LS$area <- c(0, cumsum(area[order(area, decreasing=TRUE)]))
  Flor <- apply(table[order(area, decreasing=TRUE),], 2, cumsum)
  Flor[Flor > 0] <- 1
  SLOSS$LS$species <- c(0, apply(Flor, 1, sum))
  # Calculation of SLOSS index
  SLOSS$Index <- with(SLOSS$SL, curve_area(area,
                                           species))/with(SLOSS$LS, curve_area(area, species))
  # Final object
  class(SLOSS) <- c("SLOSS","list")
  return(SLOSS)
}

curve_area <- function(x, y, bottom=0) {
  D1 <- c(diff(x))
  D2 <- c(diff(y))
  Area <- sum(D1*((y - bottom)[-length(y)]) + D1*D2/2, na.rm=TRUE)
  return(Area)
}


# edited from original function in Lexiguel to include points
plot.SLOSS <- function(x, y=NULL, sl.lty=2, sl.lwd=1, sl.col="black", ls.lty=1,
                       ls.lwd=1, ls.col="black", show.index=TRUE, digits.index=2, cex.index=1,
                       pos.index=c(0.05,0.95), show.legend=FALSE, pos.legend="bottomright",
                       bty.legend="o", main="SLOSS curves",...) {
  with(x$SL, plot(area, species, type="l", lty=sl.lty, lwd=sl.lwd, col=sl.col,
                  main=main, ...))
  with(x$LS, lines(area, species, lty=ls.lty, lwd=ls.lwd, col=ls.col))
  
  with(x$SL, points(area, species, pch = 18, cex = 1))
  with(x$LS, points(area, species, pch = 18, cex = 1))
  
  if(show.legend) {
    legend(pos.legend, lty=c(sl.lty,ls.lty), lwd=c(sl.lwd,ls.lwd),
           legend=c("small to large","large to small"), bty=bty.legend)
  }
  if(show.index) {
    with(x$SL, text(max(area)*pos.index[1], max(species)*pos.index[2],
                    labels=paste("SLOSS-index =",
                                 round(x$Index, digits.index)),
                    cex=cex.index, pos=4))
  }
}




# 
INPUT <- list_sampled_data[[10]][74][[1]]

SL_OR_SS <- function(INPUT) {
  
  table_sloss <- as.matrix(INPUT)
  area_sloss <-   table_sloss[,ncol(table_sloss)]
  
  table_sloss <- table_sloss[, - c(1, ncol(table_sloss))]
  sloss_comparison <- sloss(table_sloss, area = area_sloss)
  
  # sl <- approx(sloss_comparison$SL$area, 
  #              sloss_comparison$SL$species, 
  #              xout = seq(from = as.numeric(min(area_sloss)), to = (max(sloss_comparison$SL$area) - as.numeric(max(area_sloss))), length.out = 100), 
  #              method = "linear")
  # 
  # ls <- approx(sloss_comparison$LS$area, 
  #              sloss_comparison$LS$species, 
  #              xout = seq(from = as.numeric(min(area_sloss)), to = (max(sloss_comparison$SL$area) - as.numeric(max(area_sloss))), length.out = 100), 
  #              method = "linear")
  
  sl <- approx(sloss_comparison$SL$area,
               sloss_comparison$SL$species,
               xout = seq(from = as.numeric(max(area_sloss)), to = (max(sloss_comparison$SL$area) - as.numeric(max(area_sloss))), length.out = 100),
               method = "linear")
  
  ls <- approx(sloss_comparison$LS$area,
               sloss_comparison$LS$species,
               xout = seq(from = as.numeric(max(area_sloss)), to = (max(sloss_comparison$SL$area) - as.numeric(max(area_sloss))), length.out = 100),
               method = "linear")
  
  plot.SLOSS(sloss_comparison, show.index = F)
  points(ls, col = "blue")
  points(sl, col = "red")
  
  comparison_sloss <- as.data.frame(t(rbind(ls$y, sl$y)))
  
  comparison_sloss$outcome <- comparison_sloss$V1 - comparison_sloss$V2 # V1 is LS
  
  outcome <- if (all(comparison_sloss$outcome > 0)){
    print("SL > SS")
  } else {
    if (all(comparison_sloss$outcome < 0)){print("SS > SL")
    } else {
      print("SS = SL")
    }
  }
  
  #return(outcome)
}

SL_OR_SS(list_sampled_data[[88]][7][[1]]) # first number simulations from 1 to 100, second number dataset from 1 to 75

## ELE study


ELE_data <- list_sampled_data


for (i in 1:length(ELE_data)){
  for (j in 1: length(ELE_data[[i]])){
    
    ELE_data[[i]][j][[1]] <- SL_OR_SS(ELE_data[[i]][j][[1]])
    
  }
}

study_names <- names(ELE_data[[1]])


for (i in 1:length(ELE_data)){
  ELE_data[[i]] <- do.call(rbind.data.frame, ELE_data[[i]])
}

for (i in 1:length(ELE_data)){
  colnames(ELE_data[[i]]) <- "comparison"
}

ele_data_analysis <- do.call(rbind.data.frame, ELE_data)
ele_data_analysis$dataset_id <- rep(study_names, 100)


ele_data_analysis <- merge(ele_data_analysis, metadata, by = "dataset_id")
table(ele_data_analysis$comparison)
table(ele_data_analysis$taxa)

# only 45 studyes give SL > SS

ele_data_analysis$SS <- as.factor(ele_data_analysis$comparison)
levels(ele_data_analysis$SS)

levels(ele_data_analysis$SS)[match("SL > SS",levels(ele_data_analysis$SS))] <- "0"
levels(ele_data_analysis$SS)[match("SS = SL",levels(ele_data_analysis$SS))] <- "0"
levels(ele_data_analysis$SS)[match("SS > SL",levels(ele_data_analysis$SS))] <- "1"




ele_data_analysis$SL <- as.factor(ele_data_analysis$comparison)
levels(ele_data_analysis$SL)

levels(ele_data_analysis$SL)[match("SL > SS",levels(ele_data_analysis$SL))] <- "1"
levels(ele_data_analysis$SL)[match("SS = SL",levels(ele_data_analysis$SL))] <- "0"
levels(ele_data_analysis$SL)[match("SS > SL",levels(ele_data_analysis$SL))] <- "0"



ele_data_analysis$dataset_id <- as.factor(ele_data_analysis$dataset_id)
ele_data_analysis$sphere.fragment <- as.factor(ele_data_analysis$sphere.fragment)
ele_data_analysis$sphere.matrix <- as.factor(ele_data_analysis$sphere.matrix)
ele_data_analysis$biome <- as.factor(ele_data_analysis$biome)
ele_data_analysis$taxa <- as.factor(ele_data_analysis$taxa)
ele_data_analysis$time.since.fragmentation <- as.factor(ele_data_analysis$time.since.fragmentation)
ele_data_analysis$Matrix.category <- as.factor(ele_data_analysis$Matrix.category)


# calculate patch size evenness for every study
evenness <- list()
for (i in 1: length(list_patches)){
  evenness[[i]] <- (vegan::diversity(list_patches[[i]]$frag_size_num))/log(length(list_patches[[i]]$frag_size_num))
}

evenness <- do.call(rbind.data.frame, evenness)
evenness$dataset_id <- study_names
colnames(evenness) <- c("evenness", "dataset_id")

ele_data_analysis <- merge(ele_data_analysis, evenness, by = "dataset_id")

# calculate species richness for every study
richness <- list()
for (i in 1: length(list_patches)){
  richness[[i]] <- length(table(list_assemblages[[i]]$species))
}

richness <- do.call(rbind.data.frame, richness)
richness$dataset_id <- study_names
colnames(richness) <- c("richness", "dataset_id")

ele_data_analysis <- merge(ele_data_analysis, richness, by = "dataset_id")

# add ectothermic vs endothermic
ele_data_analysis$temperature <- ele_data_analysis$taxa

levels(ele_data_analysis$temperature)[match("amphibians & reptiles",levels(ele_data_analysis$temperature))] <- "ectotherm"
levels(ele_data_analysis$temperature)[match("birds",levels(ele_data_analysis$temperature))] <- "endotherm"
levels(ele_data_analysis$temperature)[match("invertebrates",levels(ele_data_analysis$temperature))] <- "ectotherm"
levels(ele_data_analysis$temperature)[match("mammals",levels(ele_data_analysis$temperature))] <- "endotherm"
levels(ele_data_analysis$temperature)[match("plants",levels(ele_data_analysis$temperature))] <- "ectotherm"


# add verts vs inv
ele_data_analysis$vert <- ele_data_analysis$taxa

levels(ele_data_analysis$vert)[match("amphibians & reptiles",levels(ele_data_analysis$vert))] <- "vert"
levels(ele_data_analysis$vert)[match("birds",levels(ele_data_analysis$vert))] <- "vert"
levels(ele_data_analysis$vert)[match("invertebrates",levels(ele_data_analysis$vert))] <- "invert"
levels(ele_data_analysis$vert)[match("mammals",levels(ele_data_analysis$vert))] <- "vert"
levels(ele_data_analysis$vert)[match("plants",levels(ele_data_analysis$vert))] <- "plant"

# add whether a taxon flies or not
ele_data_analysis$group <- c("bees", "bees", "lizards","orthoptera", "lepidoptera",
                             "frogs","lizards","lepidoptera", "birds", "bats", 
                             "mammals", "spiders", "bees", "bees", "amphibians",
                             "plants", "plants", "birds", "ants", "termites",
                             "mammals", "birds", "birds", "mammals", "beetles",
                             "beetles","mammals", "spiders", "spiders","spiders",
                             "mammals", "plants", "plants", "plants", "birds",
                             "bats", "spiders", "bees", "beetles", "birds",
                             "spiders", "snails", "beetles", "spiders", "mammals",
                             "amphibians","amphibians","reptiles","birds","birds",
                             "birds", "bats", "beetles", "bees", "spiders",
                             "orthoptera","beetles", "beetles","frogs", "snails",
                             "plants","bees", "plants","plants","bees",
                             "lepidoptera","mammals","lepidoptera","bats","birds",
                             "lepidoptera", "ants", "beetles", "reptiles", "lepidoptera")


ele_data_analysis$fly <- c("fly", "fly", "no_fly","fly", "fly",
                           "no_fly","no_fly","fly", "fly", "fly", 
                           "no_fly", "no_fly", "fly", "fly", "no_fly",
                           "plants", "plants", "fly", "fly", "fly",
                           "no_fly", "fly", "fly", "no_fly", "fly",
                           "fly","no_fly", "no_fly", "no_fly","no_fly",
                           "no_fly", "plants", "plants", "plants", "fly",
                           "fly", "no_fly", "fly", "fly", "fly",
                           "no_fly", "no_fly", "fly", "no_fly", "no_fly",
                           "no_fly","no_fly","no_fly","fly","fly",
                           "fly", "fly", "fly", "fly", "no_fly",
                           "fly","fly", "fly","no_fly", "no_fly",
                           "plants","fly", "plants","plants","fly",
                           "fly","no_fly","fly","fly","fly",
                           "fly", "fly", "fly", "no_fly", "fly")

ele_data_analysis$animal <- c("animal", "animal", "animal","animal", "animal",
                              "animal","animal","animal", "animal", "animal", 
                              "animal", "animal", "animal", "animal", "animal",
                              "plants", "plants", "animal", "animal", "animal",
                              "animal", "animal", "animal", "animal", "animal",
                              "animal","animal", "animal", "animal","animal",
                              "animal", "plants", "plants", "plants", "animal",
                              "animal", "animal", "animal", "animal", "animal",
                              "animal", "animal", "animal", "animal", "animal",
                              "animal","animal","animal","animal","animal",
                              "animal", "animal", "animal", "animal", "animal",
                              "animal","animal", "animal","animal", "animal",
                              "plants","animal", "plants","plants","animal",
                              "animal","animal","animal","animal","animal",
                              "animal", "animal", "animal", "animal", "animal")

ele_data_analysis$log10rich <- log10(ele_data_analysis$richness)

# Edwards 2010 is BIRDS, not PLANTS

# models
library(glmmTMB)
library(effects)


model <- glmmTMB(SS ~ 
                   #animal +
                   #vert +
                   #taxa +
                   #group +
                   #fly +
                   log10rich +
                   #richness +
                   #temperature +
                   evenness + 
                   #sphere.fragment + 
                   #sphere.matrix + 
                   #time.since.fragmentation + 
                   #Matrix.category + 
                   #biome + 
                   #(1|temperature/taxa)+
                   #(1|taxa) +
                   (1|dataset_id), 
                 data = ele_data_analysis, family = "binomial")
summary(model)
AIC(model)
#plot(model)

#plot(allEffects(model), type = "response")
plot_model <- ggpredict(model, 
                        c("evenness [all]", "log10rich [1, 1.5, 2]" ),
                        type = "re"
) 

plot(plot_model) + 
  labs(
    x = "Patch size evenness", 
    y = "Probability of SS > SL", 
    title = ""  ) + 
  labs(colour = "Log10(species richness)")

#table(ele_data_analysis$comparison, ele_data_analysis$taxa)




# ####################################################################################
# ####################################################################################
# ##
# ## JUMP FROM HERE TO ELE ANALYSIS
# ##
# ####################################################################################
# ####################################################################################
# 
# #
# 
# SETS_PATCHES <- function(db, percent) {  # db= dataset, percent = habitat amount
# 
# 
#   if (nrow(db) < 10) {
#     n_db <- 500 # 500 simulations when the number of patches in a dataset is < 10
#   } else {
#     n_db <- 100 # 100 simulations when the number of patches in a dataset is > 10
#   }
# 
#   # total habitat amount
#   target_area <- sum(db$frag_size_num) * percent
# 
#   # check how big is the largest patch in a dataset in comparison to the target area
#   target_area
#   max(db$frag_size_num)
# 
#   ## randomly select a n_db sets of patches
#   list_db <- list()
#   for (i in 1 : n_db){
#     sampled_db <- dplyr::sample_n(db,1) #sample one row
#     db2 <- db[db$frag_size_num != sampled_db$frag_size_num,] #remove that row from the table
#     while( sum(sampled_db$frag_size_num) < target_area) {
#       sampled_db2 <- dplyr::sample_n(db2,1)
#       sampled_db <- rbind(sampled_db,sampled_db2) #sample rows until target area, creating a database
#       db2 <- db2[db2$frag_size_num != c(sampled_db2$frag_size_num),] #remove that row from the table
#     }
#     list_db[[i]] <-  sampled_db
#   }
#   #
# 
#   for (i in 1:n_db) {list_db[i][[1]] <- list_db[i][[1]][order(list_db[i][[1]]$frag_size_num),]}
# 
#   list_db <- unique(list_db)
#   list_db <- rlist::list.filter(list_db, sum(frag_size_num) < (target_area + target_area*0.05) ) # a tolerance of 5% of the target area
#   #list_db <- rlist::list.filter(list_db, sum(frag_size_num) > (target_area - target_area*0.05) )
# 
#   # list_area <- list()
#   # for (i in 1 : length(list_db)) {list_area[i] <- sum(list_db[[i]]$frag_size_num)}
#   # list_area <- do.call(rbind.data.frame, list_area)
# 
#   for (i in 1: length(list_db)) {
#     list_db[[i]] <- as.data.frame(list_db[[i]]$study_and_patch)
#     colnames(list_db[[i]]) <- "study_and_patch"
#   }
# 
#   print(list_db)
#   # list_area
# }
# 
# SETS_PATCHES(list_patches[[1]], 0.3)
# 
# 
# 
# #
# #tryCatch puts NAs when error in the function (i.e., when the function cannot find)
# 
# list_simulations_twenty <- vector("list",length(list_patches))
# for (i in 1:length(list_patches)) {list_simulations_twenty[[i]] <- tryCatch(SETS_PATCHES(list_patches[[i]], 0.2), error=function(e) print(NA))}
# 
# list_simulations_forty <- vector("list",length(list_patches))
# for (i in 1:length(list_patches)) {list_simulations_forty[[i]] <- tryCatch(SETS_PATCHES(list_patches[[i]], 0.4), error=function(e) print(NA))}
# 
# list_simulations_sixty <- vector("list",length(list_patches))
# for (i in 1:length(list_patches)) {list_simulations_sixty[[i]] <- tryCatch(SETS_PATCHES(list_patches[[i]], 0.6), error=function(e) print(NA))}
# 
# list_simulations_eighty <- vector("list",length(list_patches))
# for (i in 1:length(list_patches)) {list_simulations_eighty[[i]] <- tryCatch(SETS_PATCHES(list_patches[[i]], 0.8), error=function(e) print(NA))}
# 
# 
# list_simulations <- list(list_simulations_twenty,
#                          list_simulations_forty,
#                          list_simulations_sixty,
#                          list_simulations_eighty)
# 
# 
# 
# ##
# ########################################################################################################
# ########################################################################################################
# object <- list_simulations_twenty
# 
# FINAL_FUNCTION <-function(object){ # object is one of the lists from SETS_PATCHES
# 
#   LIST_SIM <- list()
#   for (i in 1:100) {LIST_SIM[[i]] <- object}
# 
#   # merge the simulated sets of patches with the simulated assemblages in each patch
#   for (i in 1: length(LIST_SIM)) {
#     for (j in 1: length(LIST_SIM[[i]])) {
#       for (k in 1: length(LIST_SIM[[i]][[j]])){
# 
#         if (length(LIST_SIM[[i]][[j]]) > 1) {
# 
#           LIST_SIM[[i]][[j]][[k]] <- merge(LIST_SIM[[i]][[j]][[k]],
#                                            list_sampled_data[[i]][j][[1]],
#                                            by = "study_and_patch")
# 
#         } else  {
# 
#           LIST_SIM[[i]][[j]] <- NA
#         }
# 
#       }
#     }
#   }
# 
# 
# 
#   # calculate the average patch areas in each set of patches
#   LIST_SIM_area <- LIST_SIM
# 
#   for (i in 1: length(LIST_SIM_area)) {
#     for (j in 1: length(LIST_SIM_area[[i]])) {
#       for (k in 1: length(LIST_SIM_area[[i]][[j]])){
# 
#         if (!is.na(LIST_SIM_area[[i]][[j]])) {
# 
#           LIST_SIM_area[[i]][[j]][[k]] <- mean(LIST_SIM_area[[i]][[j]][[k]][,ncol(LIST_SIM_area[[i]][[j]][[k]])])
# 
#         }
# 
#       }
#     }
#   }
#   # warnings appears because every list has more than one element, so the !is.na returns multiple TRUE statements when a list is not NA
# 
#   # transform lists into tabels
#   for (i in 1:length(LIST_SIM_area)){
#     for ( j in 1: length(LIST_SIM_area[[i]])) {
# 
#       if (!is.na(LIST_SIM_area[[i]][[j]])) {
#         LIST_SIM_area[[i]][[j]] <- do.call(rbind.data.frame, LIST_SIM_area[[i]][[j]])
#         colnames(LIST_SIM_area[[i]][[j]]) <- "mean_patch_area"
#       }
#     }
#   }
# 
# 
# 
#   # calculate the species richness in each patch
#   LIST_SIM_richness <- LIST_SIM
# 
#   for (i in 1: length(LIST_SIM_richness)) {
#     for (j in 1: length(LIST_SIM_richness[[i]])) {
#       for (k in 1: length(LIST_SIM_richness[[i]][[j]])){
# 
#         if (!is.na(LIST_SIM_richness[[i]][[j]])) {
#           # take the column of each table from column two to column n-1, take their sum, and count how many times their colsum is larger than 0
#           LIST_SIM_richness[[i]][[j]][[k]] <- sum(colSums(LIST_SIM_richness[[i]][[j]][[k]][,2: (ncol(LIST_SIM_richness[[i]][[j]][[k]])-1)]) > 0)
#         }
# 
#       }
#     }
#   }
# 
# 
#   for (i in 1:length(LIST_SIM_richness)){
#     for ( j in 1: length(LIST_SIM_richness[[i]])) {
# 
#       if (!is.na(LIST_SIM_richness[[i]][[j]])) {
#         LIST_SIM_richness[[i]][[j]] <- do.call(rbind.data.frame, LIST_SIM_richness[[i]][[j]])
#         colnames(LIST_SIM_richness[[i]][[j]]) <- "richness"
#       }
#     }
#   }
# 
# 
# 
# 
# 
#   # calculate evenness in each patch
#   LIST_SIM_evenness <- LIST_SIM
# 
#   for (i in 1: length(LIST_SIM_evenness)) {
#     for (j in 1: length(LIST_SIM_evenness[[i]])) {
#       for (k in 1: length(LIST_SIM_evenness[[i]][[j]])){
# 
#         if (!is.na(LIST_SIM_evenness[[i]][[j]])) {
#           # use the HurlbertPIE function on every table, excluding patch name (column 1) and patch size (column nrow)
#           LIST_SIM_evenness[[i]][[j]][[k]] <- paleotree::HurlbertPIE(colSums(LIST_SIM_evenness[[i]][[j]][[k]][,2: (ncol(LIST_SIM_evenness[[i]][[j]][[k]])-1)]))
#         }
# 
#       }
#     }
#   }
# 
# 
# 
#   for (i in 1:length(LIST_SIM_evenness)){
#     for ( j in 1: length(LIST_SIM_evenness[[i]])) {
# 
#       if (!is.na(LIST_SIM_evenness[[i]][[j]])) {
#         LIST_SIM_evenness[[i]][[j]] <- do.call(rbind.data.frame, LIST_SIM_evenness[[i]][[j]])
#         colnames(LIST_SIM_evenness[[i]][[j]]) <- "evenness"
#       }
#     }
#   }
# 
# 
# 
# 
#   LIST_SIM_combined <- LIST_SIM_area
# 
#   for (i in 1:length(LIST_SIM_combined)){
#     for ( j in 1: length(LIST_SIM_combined[[i]])) {
# 
#       if (!is.na(LIST_SIM_combined[[i]][[j]])) {
#         LIST_SIM_combined[[i]][[j]] <- cbind( LIST_SIM_area[[i]][[j]],
#                                               LIST_SIM_richness[[i]][[j]],
#                                               LIST_SIM_evenness[[i]][[j]])
#         LIST_SIM_combined[[i]][[j]]$simulation_number <- rep(i, # give a number from 1 to 100
#                                                              nrow(LIST_SIM_combined[[i]][[j]]))
#         LIST_SIM_combined[[i]][[j]]$study <- rep(names(list_sampled_data[[i]][j]),
#                                                  nrow(LIST_SIM_combined[[i]][[j]]))
# 
#         LIST_SIM_combined[[i]][[j]]$patch_set_number = 1:nrow(LIST_SIM_combined[[i]][[j]])
# 
#       }
#     }
#   }
# 
# 
#   ## combine all studies in a table for each of the 100 simulations
#   for (i in 1:length(LIST_SIM_combined)){
#     LIST_SIM_combined[[i]] <- do.call(rbind.data.frame, LIST_SIM_combined[[i]])
# 
#   }
# 
#   LIST_SIM_combined <- do.call(rbind, LIST_SIM_combined)
#   LIST_SIM_combined <- na.omit(LIST_SIM_combined)
# 
#   final_twenty <- LIST_SIM_combined
# } # end of the function
# 
# 
# final_twenty <- FINAL_FUNCTION(list_simulations_twenty)
# final_forty <- FINAL_FUNCTION(list_simulations_forty)
# final_sixty <- FINAL_FUNCTION(list_simulations_sixty)
# final_eighty <- FINAL_FUNCTION(list_simulations_eighty)
# 
# #
# final_twenty$habitat_amount <- rep("twenty_percent", nrow(final_twenty))
# final_forty$habitat_amount <- rep("forty_percent", nrow(final_forty))
# final_sixty$habitat_amount <- rep("sixty_percent", nrow(final_sixty))
# final_eighty$habitat_amount <- rep("eighty_percent", nrow(final_eighty))
# 
# table_analysis <- rbind(final_twenty, final_forty, final_sixty, final_eighty)
# colnames(table_analysis)[5] <- "dataset_id"
# table_analysis <- merge(table_analysis, metadata, by = "dataset_id")
# 
# ##
# ## add a set of patches random effect for the same simulated sets of patches
# ##
# #
# 
# library(glmmTMB)
# library(effects)
# library(ggeffects)
# 
# table_analysis$log10ric <- log10(table_analysis$richness)
# 
# model <- glmmTMB( log10ric ~ mean_patch_area * habitat_amount + taxa +
#                     (1|dataset_id/patch_set_number) +
#                     (1|simulation_number),
#                   data = table_analysis, family = "gaussian")
# 
# 
# 
# table_analysis$evenness2 <- (table_analysis$evenness * (nrow(table_analysis)-1) + 0.5) / nrow(table_analysis)
# 
# model <- glmmTMB(evenness2 ~ mean_patch_area * habitat_amount + taxa +
#                    (1|dataset_id/patch_set_number) +
#                    (1|simulation_number),
#                  data = table_analysis, family=beta_family(link="logit"))
# 
# summary(model)
# AIC(model)
# 
# plot(allEffects(model), type = "response")
# 
# plot_model <- ggpredict(model, c("mean_patch_area", "taxa"), type = "re")
# plot(plot_model)
# 
# 
# 
# 
# ## changes in abundance
# 
# # abundance_model <- assemblages[,c(1,2,3,5)]
# # abundance_model <- abundance_model %>% summarise( abundance = mean(abundance))
# #
# # abundance_model %>%
# #   group_by(study_and_patch) %>%
# #   summarize(abundance)
# 
# ########################################################################################################
# ########################################################################################################
# ################################################################################################################################################################################################################
# ########################################################################################################
# ################################################################################################################################################################################################################
# ########################################################################################################
# ################################################################################################################################################################################################################
# ########################################################################################################
# ################################################################################################################################################################################################################
# ########################################################################################################
# ################################################################################################################################################################################################################
# ########################################################################################################
# ########################################################################################################
